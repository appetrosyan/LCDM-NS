#+TITLE: Cosmological parameter estimation using Bayesian accelerated machine learning. 
#+AUTHOR: Aleksandr Petrosyan

* Introduction

The standard cosmological model for the expansion and origin of the universe  is the accepted \Lambda{}CDM (Cold Dark Matter). It has six major parameters [TODO], which we will try to estimate. 

The measurements from which we estimate the parameters --- Planck, [TODO] contain a plethora of other less important data known as nuissance parameters, which brings the parameter space approximately up to 31 parameters. 

Among the possible approaches to estimating the parameters, of particular interest is Bayesian estimation, which allows us not only to estimate the likelihood of the parameters taking up particular values, but also estimate the validity of our model. 

In the following sections we shall outline the basics of Bayesian parameter fitting, the basics of Nested Sampling and outline the various ways in which Prior and posterior re-partitioning can speed up the convergence of Nested sampling. 

* Bayesian Parameter estimation. 

Let's assume that a scientific theory has a model for a process \(m \) which has \( n \) parameters \( \lbrace \theta \rbrace \) (drop the braces from now on). The real world observations give us a some data \( D \). 

To verify the theory we're interested in the posterior: \( P = Pr(\theta | D, M) \) and the evidence \( Z = Pr ( D | M ) \). Usuall, the predictions of the model can straightforwardly give us two things: the prior \( \pi (\theta)  = Pr (\theta | D)\) and the Likelihood \( L(\theta) = Pr ( D | \theta, M) 
) We can find those from Bayes' theorem: 

\[
Z P(\theta) = L (\theta) \pi(\theta) 
\]

Which is a straightfoward result from the theoy of probability, with profound implications. 

For a completely new theory, determining the probability of each parameter given the model is difficult, so the prior is usually uniform within some constraints. The probability of data, given the data and the model is usually a Gaussian distribution, due to the central limit theorem and the utterly huge size of the number of parameters encoded in the 31 parametes tha we're given.  Thus we can both estimate how well does our model fit the data, i.e. how certain are we that the universe is indeed \Lambda{}CDM. 
