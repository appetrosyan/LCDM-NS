\documentclass[usenatbib]{mnras}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{grffile}
\usepackage{longtable}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{textcomp}
\usepackage{amssymb}
\usepackage{capt-of}
\usepackage{hyperref}
\usepackage{rotating}
\usepackage{natbib}
\usepackage{subcaption}
\usepackage{varioref}
\usepackage{pdflscape}
\usepackage{bm}
\usepackage{pgfplots}
\usepackage{pgf}
\usepackage[nameinlink, capitalize, noabbrev]{cleveref}

\usepgfplotslibrary{groupplots,dateplot}
\usetikzlibrary{patterns,shapes.arrows}
\pgfplotsset{compat=newest}
\usepackage{dsfont}
\usepackage{xcolor}
\usepackage{listings}

\DeclareMathOperator{\TopHat}{TH}
\DeclareMathOperator{\CDF}{CDF}

\author[8275R]{Examination ID:~8275R}
\date{\today}
\title[Accelerated Nested Sampling]{Accelerated nested sampling in the context of cosmological parameter estimation}
\hypersetup{
 pdftitle={Accelerated nested sampling in context of cosmological parameter estimation},
 pdflang={English}}
\crefname{Option}{Option}{Options}
\crefname{Property}{Property}{Properties}

\newcommand{\TODO}{\textbf{TODO}}

\begin{document}

\maketitle
\begin{abstract}
  Bayesian inference is a robust framework for testing scientific
  hypotheses and is used in multiple areas of physics. In cosmology
  said hypotheses are complex, necessitating the use of Monte-Carlo
  techniques such as nested sampling. Even so, the computations
  typically require resources outside the realm of one's personal
  electronics, for example, supercomputer clusters, taking weeks to
  complete. By extending previous work, we have found a methodology
  that allows one to incorporate intuitive proposals into nested
  sampling to improve performance, called consistent posterior
  repartitioning. We have also developed a scheme for mixing several
  intuitive proposals into a single model, allowing one to extract
  only the useful information out of the combined model without risk
  of biasing the inference. We demonstrate this by comparing full
  cosmological parameter estimations done using \texttt{Cobaya} with
  and without our modifications. The performance uplift is such that
  the latter analysis was performed without loss of precision on a
  personal computer within one day, provided a well-tuned proposal
  distribution. Finally, the findings are systematised, such that
  inference techniques that are similar to nested sampling in
  benefiting from our methods, can be identified. The scope of the
  findings also suggests an extension of Bayesian analysis to multiple
  datasets simultaneously.
\end{abstract}

\begin{keywords}
Bayesian inference -- automated posterior repartitioning -- nested sampling -- cosmology: miscellaneous -- methods: statistical -- methods: data analysis
\end{keywords}

\section{Introduction}\label{sec:org14413d7}

The standard model of the universe and its evolution in modern
cosmology is the \(\Lambda\)CDM model \citep{Condon2018}, so named
after the main components of the universe: the cosmological constant
\(\Lambda\) and cold dark matter. It has six major independent
parameters: the physical baryon density \(\Omega_{b}h^{2}\); the
physical dark matter density \(\Omega_{c}h^{2}\); the value of the
Hubble parameter at present \(H_{0}\)\footnote{Equivalently the age of
  the universe \(\tau_0\), which can be inferred from the
  parameters. }; the curvature fluctuation amplitude
\(\Delta_{R}^{2}\); the scalar spectral index \(n_{s}\) and
re-ionization optical depth \(\tau_\text{reio.}\).

The task of the present study is to develop better tools for
evaluating the agreement of our observations from the Planck mission
with \(\Lambda\)CDM, estimating the parameters in the
process. Parameter estimation is convenient in the formalism of
Bayesian statistics\footnote{See \cite{xkcd} for comparison to
  frequentist statistics.}. In that language, our goal is efficient
Bayesian inference.

Many algorithms were designed to accelerate said inference:
Metropolis-Hastings \citep{Metropolis} in conjunction with the Gibbs
sampler \citep{Metropolis-Hastings-Gibbs}; Hybrid (Hamiltonian) Monte
Carlo \citep{1701.02434,Duane_1987}, and nested sampling
\citep{Skilling2006} which is our focus for the project.

Nested sampling~\citep{Skilling2006} is a family of algorithms, each
with their own unique algorithmic implementation details. The
following is a non-exhaustive list of major implementations of nested
sampling:
\begin{enumerate}
\item \texttt{MultiNest} \citep{Feroz2009MultiNestAE},
\item \texttt{PolyChord} \citep{polychord},
\item \texttt{nestle} \citep{nestle},
\item \texttt{dyNesty} \citep{Speagle_2020}.
\end{enumerate}
In this project, we shall explore a novel method for accelerating
nested sampling in general. We shall primarily present results of
testing said methods on \texttt{PolyChord}; however, we expect that
the results are transferable.

We optimised nested sampling based upon previous work by
\cite{chen-ferroz-hobson} borrowing their terminology. Briefly, it is
the observation that nested sampling is sensitive to the partitioning
of the quantity known as the
posterior. \cite{chen-ferroz-hobson} exploited this to make
inference more robust.

We, however, have discovered that it can accelerate the inference at
no loss of precision or accuracy, by extracting information out of
intuitive proposals, such as the ones typically provided with
cosmological packages. Proposal usage was previously impractical with
nested sampling, because it biased the output, and made the findings
unacceptable scientifically. We confirmed that posterior
repartitioning mitigates bias imprinting. This improved accuracy,
stability and precision of nested sampling. Additionally, since it
converges faster given more information, and proposals are more
informative by design, we exploited posterior repartitioning to
accelerate inference.

We extended \cite{chen-ferroz-hobson}'s idea of automatic power
posterior repartitioning and found several classes of consistent
partitions that offer comparable or better results but with different
trade-offs to \cite{chen-ferroz-hobson}. Furthermore, we have designed
a method of combining several such partitions into one partition, and
have shown that such a mixture can retain the benefits of all, and the
weaknesses of neither of its constituent partitions.

In the following section, we shall provide a brief primer on Bayesian
inference and nested sampling, followed by an exploration of work by
\cite{chen-ferroz-hobson}, re-contextualising it mathematically. All
work is our own from the third section onward, which includes the
mathematical framework of consistent partitions, a few examples, along
with descriptions of the underlying mechanism. We dedicate the final
sections to practical demonstrations and a few suggested applications
of our work.

\section{Theoretical background}\label{sec:orge6061a4}
In this section we primarily focus on previous work, outlining the key
points of Bayesian inference and automatic posterior
repartitioning. For more details see~\cite{jeffreys2010scientific}.
\subsection{Bayesian inference}\label{sec:primer}

A model of a physical process \({\cal M}\)\footnote{By convention all
  previous observations are implicit to the model. }, is parameterised
by \(\bm{\theta} = (\theta_{1}, \theta_{2}, \ldots , \theta_{n})\).
New empirical observations of said process are encapsulated in
\(\mathfrak{D}\). In Bayesian statistics, these objects are
represented by conditional probabilities (\cref{table-defs}). The
quantity most inextricably attached to the model is ${\cal L}$ --- the
\textbf{\emph{likelihood}} of \(\mathfrak{D}\), assuming the configuration
$\bm{\theta}$ and the model. When one data-set \(\mathfrak{D}\) is
considered, only ${\cal L}$'s the dependence on $\bm{\theta}$ is
important, so it is often represented by a multivariate function
${\cal L}(\bm{\theta})$. The probabilities of $\bm{\theta}$
configurations \textbf{\emph{prior}} and \textbf{\emph{posterior}} to inference are
$\pi(\bm{\theta})$ and ${\cal P}(\bm{\theta})$ respectively. The prior
\(\pi(\bm{\theta})\) quantifies the agreement of parameter vector
$\bm{\theta}$ with all previous observations, provided the model. The
posterior represents the same, for observations including
\(\mathfrak{D}\). The locus of all $\bm{\theta}$ for which the prior
is both defined and non-zero defines the \textbf{\emph{prior space}}
$\Psi$. Finally, the \textbf{\emph{evidence}} is the probability of the model
based on all previous observations including \(\mathfrak{D}\). The
interactions of these probabilities is governed by \citeauthor{1763}'s
theorem:
\begin{equation}\label{eq:bayes} 
 {\cal L}(\bm{\theta})  \pi (\bm{\theta}) = {\cal Z}  {\cal P} (\bm{\theta}).  
\end{equation}

Bayesian inference is the process of reconciling the model ${\cal M}$
represented in ${\cal L}$ and $\pi$, with observations
\(\mathfrak{D}\) represented in ${\cal L}$. The results of Bayesian
inference are the evidence ${\cal Z}$ and the posterior ${\cal P}$. An
implementation of Bayesian inference is called the \textbf{\emph{sampling
  algorithm}} or the \textbf{\emph{sampler}}.

The convenient representation of $\pi$ and ${\cal L}$ depends on the
particulars of the sampling algorithm. For most \textbf{\emph{nested sampling}}
(e.g. \texttt{PolyChord}, \texttt{MultiNest}) we delineate them
indirectly with log-likelihood \(\ln \cal L (\bm{\theta})\), and
\textbf{\emph{prior quantile}} \(C\{\pi\}(\bm{\theta})\). The latter, can be
thought of as a coordinate transformation
$C: \bm{u} \mapsto \bm{\theta}$ that maps a uniform distribution of
$\bm{u}$ in a unit hypercube to $\pi(\bm{\theta})$ in $\Psi$.

\begin{table}
  \caption{Definitions of main quantities in Bayesian inference.   \label{table-defs}}
\centering
\begin{tabular}{llr}
\textbf{\textbf{Term}} & \textbf{\textbf{Symbol}} & \textbf{\textbf{Definition}}\\
\hline
  Prior  & \(\pi(\bm{\theta})\) & \(P ( \bm{\theta}  \vert {\cal M})\) \\
  Likelihood  & \({\cal L}(\bm{\theta})\) & \(P ( \bm{\mathfrak{D}} \vert \bm{\theta} \cap {\cal M})\) \\
  Posterior  & \({\cal P}(\bm{\theta})\) & \(P ( \bm{\theta} \vert \bm{\mathfrak{D}} \cap {\cal M})\) \\
Evidence & \({\cal Z}\) & \(P ( \bm{\mathfrak{D}} \vert {\cal M})\) \\
\end{tabular}
\end{table}


For Bayes' theorem to hold, the domains of all functions need to be
the same. Let \(D(f)\) denote the domain of the probability density
function \(f\), i.e.~where \(f\) is both defined and
\textbf{non-zero}. Hence
\begin{equation}
  D(\pi) \cap D({\cal L})  = D({\cal P}) \subset \Psi,
\end{equation} 
meaning the inference is possible only on a subset of the domain of
the prior and likelihood.\label{domain-discussion}

A crucial insight by \cite{chen-ferroz-hobson}, is that for each
choice of ${\cal L}$ and $\pi$, there is a unique choice of ${\cal Z}$
and ${\cal P}$; equivalently they represent the same unique model
${\cal M}$. This correspondence is \emph{surjective}, but not
\emph{injective}: many choices of \({\cal L}(\bm{\theta})\) and
\(\pi (\bm{\theta})\) may correspond to the same
\( {\cal P} (\bm{\theta})\) and \({\cal Z}\).


\subsection{Nested Sampling}\label{sec:org36366f8}

By noting that ${\cal P}$ is a probability, hence normalised, from
\cref{eq:bayes} we obtain
\begin{equation}
  \label{eq:def-z}
  {\cal Z} = \int_{\Psi} {\cal L}(\bm{\theta}) \pi(\bm{\theta}) d\bm{\theta}. 
\end{equation}
Thus, \citeauthor{1763}'s theorem reduces parameter estimation ---
obtaining ${\cal P}$ from $\pi$ and ${\cal L}$, to
integration~\citep{bayes-integration}. The naïve approach: uniformly
rasterise \(\Psi\) and obtain \({\cal Z}\) via Riemann sums, is valid
though intractable for hypotheses with \(O(30)\) parameters
\citep{Caflisch_1998}. Integration is thus performed using Monte Carlo
techniques, such as nested sampling.

The gist of the algorithm \citep{Skilling2006} is to pick \textbf{\emph{live
  points}} at random in $\Psi$. Based on a well-defined prior- and
implementation-dependent principle (\cref{sec:ns}) iteratively move
said points into regions of high likelihood. A statistical argument
allows approximating ${\cal Z}$ and its error during each
iteration. Ergo, by \cref{eq:bayes}, ${\cal P}(\bm{\theta})$ and its
error are also found. The process terminates whenever a predetermined
accuracy of ${\cal Z}$ is achieved, often controlled by the errors.

Thus, nested sampling, unlike, e.g.~Metropolis-Hastings
\cite{Metropolis-Hastings-Gibbs} is sensitive to the concrete
definitions of prior and likelihood. While many choices of $\pi$ and
${\cal L}$ correspond to the same ${\cal P}$ and ${\cal Z}$, nested
sampling's time complexity is different for different specifications
of $\pi$\citep{Skilling2006}. In particular, for more
\textbf{\emph{informative}} priors (quantified by global maximum probability
density) convergence occurs faster.

The time complexity $T$ of nested sampling satisfies
\begin{equation}\label{eq:complexity}
  T \propto  n_\text{live}\  \langle {\cal T}\{{\cal L}(\bm{\theta})\} \rangle \ {\cal N}\{{\cal L}(\bm{\theta}) \},
\end{equation}
where ${\cal T}\{f(\bm{\theta})\}$ represents time complexity of
evaluating $f(\bm{\theta})$ and ${\cal N}\{f(\bm{\theta})\}$, the
number of such evaluations. Reducing $n_\text{live}$ reduces the
resolution of nested sampling, while
$ {\cal T}\{{\cal L}(\bm{\theta})\}$ is model-dependent. We can,
however, reduce the number of likelihood evaluations, by providing a
more informative prior. However, there is an associated risk, which
precludes use of proposals as informative priors.

An important quantity for measuring the correctness of the obtained
posterior is the \textbf{\emph{Kullback-Leilber divergence}} ${\cal D}$
\citep{Kullback_1951}. For probability distributions
\(f(\bm{\theta})\) and \(g(\bm{\theta})\), it is defined as:
\begin{equation}
  \label{eq:kl-def}
  {\cal D}\{f, g \} = \int_{\Psi}f(\bm{\theta}) \ln \frac{f(\bm{\theta})}{g(\bm{\theta})} d \bm{\theta}.
\end{equation}
It is a pre-metric on the space of probability distributions: it is
nil if and only if $f(\bm{\theta}) = g(\bm{\theta})$, but is not
symmetric. This is convenient for defining a representation
hierarchy. The statement: $f$ represents $g$ better than $h$ is
equivalent to
\begin{equation}
  \label{eq:hierarchy}
  {\cal D}\{f, g\} < {\cal D}\{h, g\}.
\end{equation}
Specifically, distribution $h$ is said to be unrepresentative of $g$
if a uniform distribution $f$ represents $g$ better than $h$ does.

The representation of ${\cal P}$ and $\pi$ is crucial for nested
sampling's correctness and performance. For example, if $\pi$ and
$\pi'$ are equally informative, but $\pi$ is more representative of
${\cal P}$, then the inference with $\pi$ will terminate more quickly
than with $\pi'$, and will be more accurate.

Similarly, if $\pi'$ is more informative than $\pi''$, but equally as
representative, nested sampling will terminate with $\pi'$ faster than
with $\pi''$, and the result will be more precise. If
\(\pi' (\bm{\theta})\) is more similar to \( {\cal P} (\bm{\theta})\),
then points drawn with PDF \(\pi' (\bm{\theta})\) are more likely to
lie in $\bm{\theta}$ regions of high \( {\cal P} (\bm{\theta})\),
leading to fewer iterations. However, posteriors ${\cal P}$ obtained
with different priors are different by \cref{eq:bayes}. In fact, the
posterior ${\cal P}'$ will be more informative than ${\cal P}''$, and
more similar to $\pi'$. This we call \textbf{\emph{bias imprinting}}.


Imprinting can be desirable if the informative prior $\pi'$ is the
result of multiple inferences over multiple datasets. However, even in
such a case imprinting limits the information obtainable from
\(\mathfrak{D}\), manifesting confirmation bias if $\pi$ is not
representative. The risk of getting no usable data from the inference
is sufficient to prefer uniform priors even when more information is
available.
\subsection{Power posterior repartitioning}\label{sec:autopr}
We are working under the assumption that $\pi(\bm{\theta})$ is an
informative, unrepresentative prior. To avoid loss of precision and
mitigate bias imprinting, \cite{chen-ferroz-hobson} have proposed
introducing the parameter \(\beta\) to control the breadth of the
informative prior:
\begin{equation}
  \label{eq:autopr-prior}
  \hat{\pi}(\bm{\bm{\theta}};\beta) = \cfrac{\pi(\bm{\theta})^{\beta}}{Z(\beta)\{\pi\}},
\end{equation}
(see \cref{fig:ppr}) where \(Z(\beta)\{\pi\}\) --- a functional of
\(\pi (\bm{\theta})\) is a normalisation factor for
\( {\cal P} (\bm{\theta})\), i.e.
\begin{equation}
  Z(\beta)\{\pi\} = \int_{\Psi} \pi(\bm{\bm{\theta}})^{\beta}d\bm{\bm{\theta}}.
\end{equation}
In their prescription, the likelihood changes to
\begin{equation}
  \hat{\cal L}(\bm{\theta}; \beta) = {\cal L}(\bm{\theta}) Z(\beta)\{\pi\} \cdot \pi^{1-\beta}(\bm{\theta}).
\end{equation}
The new parameter $\beta$ is treated as any other non-derived
parameter of the original theory.

\begin{figure}
 \input{./illustrations/ppr.tex}
 \caption{\label{fig:ppr} Demonstration of
   \(\hat{\pi}(\theta; \beta)\) for different values of \(\beta\) in
   one dimension. Note that we've assumed that the original
   \( \pi (\bm{\theta})\) distribution is a truncated Gaussian,
   i.e.~zero outside the region \((-1, 1)\), which manifests as
   changes in curvature at the boundaries. The area under curves for
   different $\beta$ is normalised to unity as in
   \cref{eq:autopr-prior}. }
\end{figure}

Note, that
\({\cal L}(\bm{\theta})\pi (\bm{\theta}) = \hat{\cal L}(\bm{\theta}
\hat{\pi} (\bm{\theta})\) by construction, hence from \cref{eq:bayes}
the posterior and evidence corresponding to
\(\hat{\cal L}(\bm{\theta};\beta)\) and
\(\hat{\pi} (\bm{\theta};\beta)\) will be the same as
\( {\cal P} (\bm{\theta})\) and \({\cal Z}\), corresponding to the
original $\pi(\bm{\theta})$ and ${\cal L}(\bm{\theta})$.  In practice,
however, if the original prior \(\pi (\bm{\theta})\) were unrepresentative
of the posterior \( \bar{\cal P} (\bm{\theta})\), leading to
significant errors in ${\cal Z}$ and
${\cal P}(\bm{\theta}) \ne \bar{\cal P}(\bm{\theta})$.  However,
$\hat{\pi}$ may become representative for some value of
$\beta = \beta_{R}$. Values $\beta$ close to $\beta_{R}$
correlate with higher likelihoods, thus the sampler prefers
them. Hence, the system will converge to a state where
\( {\cal P} (\bm{\theta})\) is represented in
\(\hat{\pi} (\bm{\theta};\beta)\)\footnote{Technically we obtain
  \( \hat{\cal P} (\bm{\theta};\beta)\) which, when marginalised over
  $\beta$, yields
  \( {\cal P} (\bm{\theta}) = \int \hat{\cal P} (\bm{\theta};\beta) d
  \beta\) --- the correct posterior.}.

\cite{chen-ferroz-hobson} dubbed this \textbf{\emph{automatic power posterior
  repartitioning}}(PPR) because the choice of
$\beta\rightarrow\beta_{R}$ is automatic. It mitigates the loss
precision and thus accuracy for unrepresentative informative priors
$\pi$, by sacrificing performance.


\section{Theoretical discoveries}
In this section we shall be working under the inverted premise of
\cref{sec:autopr}: gaining performance without sacrificing accuracy or
precision.

\subsection{Biases\label{discussion-bias}}


Knowing that nested sampling converges faster for more informative
priors, why do we almost always use the least informative priors?
Mainly, because this often accurately represents our prior knowledge
\citep{JeffreysPrior}. Sometimes, however, even when we do have
informative priors obtained as posteriors from previous datasets, we
use a uniform prior \(\pi (\bm{\theta})\) with nested sampling, out of
fear of biasing the inference. From \cref{eq:bayes}, we see that
preserving the functional form of \( {\cal L} (\bm{\theta})\), the
choice of \( \pi (\bm{\theta})\) directly affects the results.

Moreover, if \( \pi (\bm{\theta})\) is unrepresentative of
\( \bar{\cal P}(\bm{\theta})\) corresponding to
\( \bar{\pi} (\bm{\theta}) = \text{Const.}\) and
\( {\cal L} (\bm{\theta}) = \bar{\cal L} (\bm{\theta})\), the shape of
\( {\cal P}(\bm{\theta})\) will have a strong imprint from
\( \pi (\bm{\theta})\). In other words, by sampling an informative
bias, we mostly obtain information from the bias
\cref{fig:convergence}.  The utility of such inference is comparable
to that of the famous Venera-14\footnote{After touchdown, the lander's
  lens caps had fallen precisely where the probe was going to take the
  first and only sample of Venusian soil. Consequently, the rather
  expensive mission to Venus obtained mediocre measurements of earth
  rubber's compressibility.  } mission.

However, we can sidestep this issue. Power Posterior repartitioning
fully compensates for \( \pi (\bm{\theta})\) that peaks at
approximately the same $\bm{\theta}$ location as
\( {\cal P}(\bm{\theta})\), but is broader or narrower, by allowing
the breadth of \( \hat{\pi} (\bm{\theta};\beta)\) to vary.

\subsection{Intuitive proposals and accelerated convergence\label{sec:accelerating}}
Now consider the following premise: we're given a model \({\cal M}\),
for which our prior is not quite
\(\bar{\pi}(\bm{\theta}) = \text{Const.}\). This usually means that
from other sources, e.g.~other inferences, physical reasoning, etc.,
we are provided with
\begin{equation}
  \pi (\bm{\theta}) = f(\bm{\theta}; \bm{\mu}, \bm{\Sigma}),
 \label{eq:bias}
\end{equation}
which is representative of the posterior
\(\bar{\cal P}(\bm{\theta})\). Here, the probability density function
$f$ is parameterised by \(\bm{\mu}\) in its location and
\(\bm{\Sigma}\) its breadth. In order to obtain the same result as one
would have with the less informative uniform prior
\(\bar{\pi}(\bm{\theta})\), one needs to adjust the likelihood
${\cal L}$. Recall, that the reason why PPR obtains the same posterior
\( \bar{\cal P}(\bm{\theta})= \hat{\cal P}(\bm{\theta})\) as one would
have using \( \bar{\pi} (\bm{\theta}) = \text{Const.}\) is because
\( \hat{\cal L} (\bm{\theta};\beta)\) and
\( \hat{\pi} (\bm{\theta};\beta)\) are a \textbf{\emph{consistent
  (re)partitioning}} of \( \bar{\cal Z}\) and
\({\cal P}(\bm{\theta})\). That is:
\begin{equation}
  \label{eq:partitioning}
  \int_{\Psi} \hat{\cal L} (\hat{\bm{\theta}}) \hat{\pi} (\bm{\hat{\theta}}) d\hat{\bm{\theta}}  = \int_{\Psi}\bar{\pi} (\bm{\theta}) \bar{\cal L} (\bm{\theta}) d\bm{\theta} = \bar{\cal Z}, 
\end{equation}
where in the case of PPR
$\hat{\bm{\theta}} = (\theta_{1}, \theta_{2}, \ldots, \theta_{n},
\beta)$. \Cref{eq:partitioning} holds if
\begin{equation}
  \label{eq:partitioning-p}
  \hat{\cal L}(\bm{\theta};\beta) \hat{\pi}(\bm{\theta};\beta)  = \bar{\cal L}(\bm{\theta})\bar{\pi}(\bm{\theta}) 
\end{equation}
for all $\beta$, by \cref{eq:bayes}. Note that
\cite{chen-ferroz-hobson} have used \cref{eq:partitioning-p} as the
primary expression. Following their convention, we shall sometimes
refer to consistent partitions as posterior repartitioning, rather
than evidence repartitioning\footnote{See \cref{sec:resizeable} for an
  example of where evidence repartitioning is a more accurate
  description.}.

PPR accelerates convergence in the following way. Each iteration
obtains a larger evidence estimate, so fewer are needed to reach the
termination point (See~\cref{fig:benchmark}). There is a competing
mechanism: the evidence estimates accumulate fewer errors, so
inference proceeds longer before the precision loss triggers
termination (\cref{fig:higson}). Thus repartitioning reaches a more
precise result quicker, but can reach a result of similar precision
quicker still.

\subsubsection{Example: intuitive proposal posterior repartitioning}
Suppose that from a different inference, one has obtained
the posterior \({\cal P}(\bm{\theta})\). Under these circumstances,
\begin{subequations}
\begin{equation}
  \label{eq:iPPR}
 \hat{\pi}(\bm{\theta}) = f(\bm{\theta}, \bm{\mu}, \bm{\Sigma}) = {\cal P}(\bm{\theta}), 
\end{equation}
is an informative prior that represents our knowledge: it is an
\textbf{\emph{intuitive proposal}}. However, we wish to avoid biasing the
inference and use the (usually uniform) prior
$\bar{\pi}(\bm{\theta})$, with likelihood $\bar{\cal L}(\bm{\theta})$.

To obtain with $\hat{\pi}(\bm{\theta})$ the same posterior and
evidence as one would have with $\bar{\pi}(\bm{\theta})$ and
$\bar{\cal L}(\bm{\theta})$, the partitioning of the (evidence) needs
to be \textbf{\emph{consistent}} with the reference model where
$\bar{\pi}(\bm{\theta})$. Specifically:
\begin{equation}
  \label{eq:ippr-l}
  \hat{\cal L}(\bm{\theta}) = \frac{\bar{\pi}(\bm{\theta}) \bar{\cal L}(\bm{\theta})}{{\cal f}(\bm{\theta}; \bm{\mu}, \bm{\Sigma})}.
\end{equation}
\end{subequations}
This we call \textbf{\emph{intuitive proposal posterior\footnote{More
    accurately evidence repartitioning, which is equivalent where
    there's not re-parametrisation besides adding or removing
    parameters.} repartitioning}} (iPPR). It is the fastest possible
and the least robust consistent partitioning scheme, which both stem
from a peculiarity of nested sampling: it estimates the evidence up to
an error. If our evaluation of ${\cal Z}$ were exact, \cref{eq:bayes}
would guarantee the correct posterior. Because we allow errors in
${\cal Z}$, several scenarios are possible.

If the reference posterior were largely the same as $\hat{\pi}$, or
located in the same region, but broader, then the inference obtains
the same, or possibly more accurate (and precise) posterior, caused by
more precise evidence.

If $\hat{\pi}$ were narrower than $\bar{\cal P}$ and representative,
points are more likely to have been spawned inside high likelihood
regions, thus nested sampling may never have probed the regions of
lesser likelihood. As a result, the obtained posterior $\hat{\cal P}$,
may be narrower than the reference $\bar{\cal P}$, and will not
contain any information about the low $\hat{\cal L}$ regions. This
effect is \textbf{\emph{bias imprinting}}.

Lastly, if there is a significant offset between $\hat{\pi}$ and
${\cal P}$, i.e. $\hat{\pi}$ is unrepresentative of ${\cal P}$, the
errors in ${\cal Z}$ dominate termination. Since the probability of
choosing a live point at the posterior peak \(\bm{\theta}_{{\cal P}}\)
is proportional to $\hat{\pi}(\bm{\theta}_{{\cal P}})d\bm{\theta}$ for
\(d\bm{\theta}\) infinitesimal in that region, the posterior peak may
be probed very rarely. As a result the marginalised posterior
$\hat{\cal P}$, will mostly resemble $\hat{\pi}$. We, thus, observe
severe bias imprinting.

PPR copes with the first and the second case and to a lesser extent
the third. In the next sections, we shall explore why that is, and
present methods explicitly designed to mitigate prior imprints.
\subsection{General automatic posterior repartitioning}\label{sec:gapr}

In this section, we look at the family of methods similar to PPR and
iPPR called consistent repartitioning. We note which schemes are more
useful for the task of accelerating nested sampling without biasing
the posterior. Begin by noting, \Cref{eq:partitioning} alone does not
guarantee correct convergence: iPPR and PPR converge correctly under
some circumstances and not others.

We shall consider a general consistent partitioning
\(\hat{\pi}, \hat{\cal L}\) with re-parametrisation
\(\hat{\theta}\). Because $\theta \ne \hat{\theta}$, generally, the
posterior \({\cal P}(\bm\hat{\theta})\) would not have the same
functional form as \(\bar{\cal P}(\bm{\theta})\). Nonetheless, if
inverting the parametrisation from $\bm{\hat{\theta}}$ to $\bm{\theta}$
is possible, and under that procedure $\hat{\cal P}$ maps to
${\cal P}$, we shall say that $\hat{\cal P}$ is marginalised to
${\cal P}$. Thus, the correct posterior is one that marginalises to
$\bar{\cal P}$. We shall often use $\hat{\cal P}(\bm\hat{\theta})$ and
${\cal P}(\bm{\theta})$ that it marginalises to, interchangeably.

We can rigorously prove\footnote{Albeit in more than 5,000 words.},
that the following conditions are necessary for a consistent
partitioning to yield the correct posterior and evidence through
Bayesian inference.
\begin{enumerate}
\item \textbf{Consistency}. The partitioning is consistent
  i.e.~satisfies \cref{eq:partitioning}. \label[Property]{norm-prop}

\item \textbf{Representation}. In prior hyperspace
  $\hat{\Psi} \supset \Psi$ there exists a subspace
  $\Psi_{R} \subset \hat{\Psi}$, such that for all
  $\hat{\bm{\theta}}\in \Psi_{R}$, \( {\cal P}(\bm{\theta})\) is
  represented in \( \hat{\pi} (\bm{\hat{\theta}})\). In other words,
  the re-parameterised prior includes a representative
  configuration. \label[Property]{spec-prop}
  
\item \textbf{Convergence}. The sampling favours representative
  configurations $\bm\hat{\theta} \in
  \Psi_{R}$. \label[Property]{vconv-prop}
\item \textbf{Objectivity}. The prior bias (towards
  \(\hat{\pi}(\bm{\hat{\theta}})\)) is weaker than the posterior bias
  (towards \(\hat{\cal P}(\bm{\hat{\theta}})\)). \label[Property]{obj-prop}
\end{enumerate}
Note that these properties are contingent on the sampling
algorithm. For example, in the case of inference by integration
${\cal Z}$ using uniform rasterisation, all properties follow from
\cref{eq:partitioning}. Not so for a class of algorithms that estimate
${\cal Z}$ by controlled error propagation and approximation,
e.g.~nested sampling. Thus, understanding the circumstances wherein
these conditions are violated, may clarify the circumstances where
both PPR and iPPR fail to produce the expected result.

Firstly, they satisfy \cref{norm-prop} by construction. iPPR satisfies
\cref{spec-prop} if and only if \( \hat{\pi} (\bm{\theta})\)
represented the correct posterior to begin with, in which case
$\Psi_{R} = \Psi$. \Cref{vconv-prop} follows from the correctness
proof of nested sampling, \citep{Skilling2006} and \cref{norm-prop} if
\cref{spec-prop} is also satisfied. In \cref{sec:autopr} we have shown
that PPR satisfies \cref{spec-prop}, where
$\Psi_{R} = \{ \beta = \beta_{R} = \text{Const.}\}$, if $\beta_{R}$
exists. There's always at least one:
$\Psi_{R} = \text{Locus}\{ \beta_{R}=0 \} \cap \Psi$, but we are
interested in values of $\beta_{R} > 0$, as such priors are more
informative. In that section we have provided an intuitive explanation
for why PPR has \cref{vconv-prop}.

However, this does not guarantee the correct posterior, indeed in
\cref{fig:convergence}, we see that both $\theta_{0}$ and $\theta_{2}$
marginalised posteriors are offset from the correct result obtained
using $\bar{\pi}(\bm{\theta})=Const.$. This is an illustration, of the
importance of \cref{obj-prop}, as the test case \cref{fig:convergence}
was constructed to violate it specifically.


\subsection{Isometric mixtures of repartitioning schemes}
In this section we shall consider two methods of combining several
proposals (consistent partitions) into one (consistent
partition). Identifying the posterior to which points in $\Psi$
correspond to by \cref{eq:bayes}, as a metric, the mixture is
isometric: the metric in the new, parameterised space marginalises to
the original metric ${\cal P}$.


\subsubsection{Additive isometric mixtures}\label{sec:org418133f}
Consider \(m\) consistent repartitioning schemes of the same
posterior \(\bar{\cal P}(\bm{\theta})\):
\begin{equation}
  \label{eq:collection-of-models}
  \hat{\cal L}_{1}(\bm{\theta}) \hat{\pi}_{1}(\bm{\theta}) = \hat{\cal L}_{2}(\bm{\theta}) \hat{\pi}_{2}(\bm{\theta})= \ldots =\hat{\cal L}_{m}(\bm{\theta}) \hat{\pi}_{m}(\bm{\theta}). 
\end{equation}
Their \textbf{\textbf{\emph{isometric mixture}}}, is a consistent partitioning that involves information
from each constituent prior.

For example: \textbf{\emph{additive isometric mixture}} \cref{fig:additive}, defined as
\begin{subequations}
  \begin{alignat}{2}
    \hat{\pi}(\bm{\theta}; \bm{\beta}) = &\sum_{i} \beta_{i} \hat{\pi}_{i}(\bm{\theta}),\label{eq:additive-mix}\\
    \hat{{\cal L}}(\bm{\theta}; \bm{\beta}) = &\frac{\sum_{i}   \beta_{i} \hat{\pi}_{i}(\bm{\theta}) \hat{\cal L}_{i}(\bm{\theta})}{\sum_{i} \beta_{i} \hat{\pi}_{i}(\bm{\theta})},
  \end{alignat}
\end{subequations}
parameterised by
$\bm{\beta} = (\beta_{1}, \beta_{2}, \ldots, \beta_{m})$ where each
$\beta_{i} \in [0,1]$. It is a consistent partitioning if and only if
$\sum_{i} \beta_{i} = 1$.

\begin{figure}
  \input{illustrations/additive_mixtures.tex}
  \caption{\label{fig:additive} An additive isometric mixture of a
    Gaussian iPPR and a uniform reference. Gaussian PPR added for comparison.}
\end{figure}

Isometric mixtures are an attempt to relax some of the limitations
imposed by PPR. Firstly, proposals in PPR form are limited to a class
of functions linked by a power relation. This class always includes a
uniform prior, but not, for example, a ``wedding cake'' prior (stepped
uniform prior). Additive mixtures allow such proposals. Moreover, in
additive isometric mixtures, all consistent partitions are compatible
provided their domains match $\Psi$.

However, additive mixtures have limited utility: they are slow,
difficult to implement and susceptible to numerical instability more
than any other consistent partitioning. In lieu of exploring other
partitions similar to PPR (e.g.~\cref{sec:orgfe92f25}), in the next
section we shall diagnose and compensate the aforementioned issues.

\subsubsection{Stochastic superpositional isometric mixtures}

One major problem with additive mixtures lies in the definition of
$\hat{\cal L}$. Instead of having to evaluate only one of the
constituent likelihoods, we are forced to evaluate all of them. This
sets a lower bound on time complexity
\begin{equation}
  {\cal T}\{\hat{\cal L}\} = o \left(   \max_{i} {\cal T}\{ {\cal L}_{i}\} \right).\label{eq:hard-cap}
\end{equation}
This is close to the average case when the likelihoods are all related
to the same reference (e.g.~$\bar{\cal L}$) with only minor
corrections computed to account for different proposals. However if
${\cal L}_{i}$ and ${\cal L}_{j}$ have no common computations that can
be re-used, the average case time complexity is
\(o({\cal T}({\cal L}_{i})+ {\cal T}({\cal L}_{j})\).


Another issue is that the overall likelihood depends on the prior PDFs
of the constituents. This is problematic since nested sampling
requires specification of the prior via its quantile
\cite{Skilling2006,polychord,multinest}. Function inversion is not
linear with respect to addition, so the quantile of the weighted sum
needs to be evaluated for each type of mixture individually. For a
linear combination of uniform priors, evaluating the quantile can be
done analytically, but not in case of two Gaussians or a Gaussian
mixed with a uniform. By contrast, the quantile of PPR with an
uncorrelated\footnote{This is problematic for a correlated Gaussian,
  but every correlated covariance matrix can be diagonalised, which we
  make part of the parametrisation.}  Gaussian proposal is found in
closed form.

The idea is to avoid mathematical operations that require evaluation
of all of the constituents' priors/likelihoods. This naturally leads
to deterministic prior branching. This circumvents the difficulties
with determining the quantile of the mixture. If the probability of
said choice can be tuned using a parameter, it can be made part
$\hat{\bm{\theta}}$ similarly to $\beta$ in PPR.

Hence, we propose that a \textbf{\emph{superpositional mixture}}, defined via
the following parametrisation:
\begin{subequations}
\begin{equation}
  \hat{\pi}(\bm{\theta}; \bm{\beta})  =
  \begin{cases}
	\hat{\pi}_{1}(\bm{\theta}) & \text{with probability } \beta_{1},\\
	& \vdots\\
	\hat{\pi}_{n}(\bm{\theta}) & \text{with probability } (1- \sum_{i}^{m}\beta_{i}),
	\end{cases}
\end{equation}
\begin{equation}
  \hat{\cal L}(\bm{\theta}; \bm{\beta})  =
  \begin{cases}
	\hat{\cal L}_{1}(\bm{\theta}) &  \text{with probability } \beta_{1},\\
		    &\vdots\\
	\hat{\cal L}_{m}(\bm{\theta}) & \text{with probability} (1- \sum_{i}^{m}\beta_{i}).
\end{cases}
\end{equation}
is isometric, if and only if
\begin{equation}
  \label{eq:sspr}
  \hat{\pi}(\bm{\theta}; \bm{\beta}) = \hat{\pi}_{i}(\bm{\theta}) \Leftrightarrow \hat{\cal L}(\bm{\theta}; \bm{\beta}) = \hat{\cal L}_{i}(\bm{\theta}; \bm{\beta}), 
\end{equation}
\end{subequations}
that is, the branches are chosen consistently. 

The~\cref{spec-prop} is satisfied, if any of the priors $\hat{\pi}$
represented the posterior. The~\cref{vconv-prop} is satisfied
similarly to PPR: the likelihood is determined by
\(\bm\hat{\theta} \supset \bm{\beta}\), so $\bm{\beta}$s that lead to
higher likelihoods are favoured, ergo configurations representing
${\cal P}$ are preferred.

Superpositional mixtures have multiple advantages when compared with
additive mixtures. Crucially, only one of ${\cal L}_{i}$ is evaluated
each time $\hat{\cal L}$ is evaluated. As a result, ignoring the
overhead of branch choice, the worst-case time complexity is the same
if not better than the best case for additive mixtures. This has vast
implications discussed in \cref{sec:applications}.

Moreover, the superpositional mixture's branch choice is external to
the likelihoods and independent of them. Consequently, specifications
of $\hat{\pi}_{i}$ via quantile are sufficient, and no further
calculations are required from the end-user.

There can be many implementations of a superpositional mixture. A
natural first choice would be a quantum computer, where the
$\hat{\pi}$ and $\hat{\cal L}$ are represented by \(m\) level systems
entangled with each other (consistent branching) and a classical
computer (to evaluate ${\cal L}$ and $\pi$). However, we can also
attain an implementation using only computational methods via a
stochastic choice.

\textbf{\emph{Stochastic superpositional isometric mixture}} of consistent
partitioning (SSIM) ensures branch consistency by requiring
\begin{equation}
\hat{\pi}(\bm{\theta}; \bm{\beta}) = \hat{\pi}_{F(\bm{\theta};
  \bm{\beta})}(\bm{\theta};\bm{\beta}),
\end{equation}
where
$F: (\bm{\theta}, \bm{\beta}) \mapsto i \in \{1, 2, \ldots, m-1\}$. In
our implementation it is a niche-apportionment random number generator
(sometimes called the broken stick model), seeded with the numerical
\texttt{hash} of the vector $\bm{\theta}$, illustrated in
\cref{fig:mixture}.

SSIM also relaxes the requirement on the domains of the proposals:
they no longer need to coincide, as opposed to e.g.~ additive
mixtures.  It is also much more robust, which we shall discuss in the
later sections. It does, nevertheless, come with one drawback. As a
result of branching, the likelihood $\hat{\cal L}$ visible to the
sampler, is no longer continuous (\cref{fig:mixture-3d}). Thus a
nested sampling implementation that relied on said continuity will
have undefined behaviour. \texttt{PolyChord}'s slice sampling seems
not affected by the discontinuity, but there may be other samplers
that are.
\begin{figure}  
  \input{./illustrations/mixture_2.tex}

  \input{./illustrations/mixture_3.tex}

  \input{./illustrations/mixture_4.tex}
  \caption{An example of mixture repartitioning. The mixture is not
    normalised to emphasise the coincidence of values with both the
    uniform distribution and a Gaussian. $\beta$ controls the
    probability of belonging to the Gaussian in the stochastic
    mixture.  Additionally, the resolution is deliberately reduced, to
    contrast behaviour of all three at the truncation
    boundary. \label{fig:mixture}}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=0.9\columnwidth]{./illustrations/SSIM_3d.pdf}
  \caption{An illustration of SSIM in two dimensions. Colour represents the value of $\pi(\bm{\theta})$. As a result of nested sampling, nucleation of the representative phase is dynamically favoured.}
  \label{fig:mixture-3d}
\end{figure}


\section{Measurements and methodology}
We shall adopt the weighted accounting approach \citep{Cormen} for
measuring time complexity in units of \({\cal N}\{{\cal L}\}\), and
reducing all quantities to their long-run averages. Consequently, all
of the repartitioning schemes' overheads associated with internal
implementation details are ignored. This puts additive mixtures at an
inherent disadvantage, because in the average case,
\begin{equation}
  \label{eq:additive-t-complexity}
  {\cal N}\{ \hat{\cal L}\} = \sum_{i}^{m} {\cal N}\{{\cal L}_{i}\}, 
\end{equation}
without modifications to the nested sampler's internals.


We shall use Kullback-Leibler divergence in multiple contexts. First,
${\cal D}\{\pi, {\cal P}\}$ --- a measure of information obtained from
the dataset ignoring the prior. If the proposal fully agrees with the
data, ${\cal D}\{ \pi, {\cal P} \} \approx 0$.  \Cref{fig:kl-scaling}
clearly shows that it is also a reliable predictor of performance. In
\cref{fig:kl-d}, we see that the amount of information extracted from
PPR increases with increased offset. However, it does so sub-linearly,
which combined with \cref{fig:convergence}, renders the validity of
the obtained posteriors from PPR and SSIM, suspect. Thus we need a
method of comparing posteriors to determine their accuracy.

Second, we use ${\cal D}\{ {\cal P}, \bar{\cal P} \}$ to quantify the
correctness of the obtained posterior, where $\bar{\cal P}$ is the
posterior obtained using a $\bar{\pi}(\bm{\theta}) = \text{Const}$. We
also use ${\cal Z}$ to gauge correctness.

From \cref{eq:bayes}, errors in ${\cal P}$ are necessarily caused by
errors in estimating ${\cal Z}$, and is the crucial reason why nested
sampling is sensitive to partitioning in the first instance. Moreover,
the character of error in ${\cal Z}$ indicates the type of error in
${\cal P}$. A higher than expected evidence ${\cal Z}$ is indicative
of inconsistent partitioning, where the likelihood was not re-scaled
to accommodate a more informative prior (\cref{fig:hist}). A less than
expected ${\cal Z}$ indicates that the regions of high ${\cal L}$ were
not probed sufficiently. Usually, this is accompanied by bias
imprinting as with PPR in \cref{fig:convergence}.

\begin{table}
  \centering
  
  \caption{Typical values of posterior-to-reference-posterior
    Kullback-Leibler divergence ${\cal D}\{{\cal P}, \bar{\cal P}\}$
    for the runs shown in \cref{fig:hist}. The inconsistent
    re-sizeable uniform had not been given an improper normalisation
    of $\hat{\cal L} = {\cal L}$. It is of type \textbf{\emph{Re-sizeable
      uniform}} described in \cref{sec:resizeable}.}
  \begin{tabular}{lrr}
    \textbf{Scheme} & ${\cal D}\{ {\cal P}, \bar{\cal P}\}$ & ${\cal Z}$\\
    \hline
    Uniform & 0.000 & \(-62.3 \pm 0.30\)\\
    Analytical & 0.000 & \(-62.32 \pm 0.00\) \\
    $R$ & 0.724 & \(-54.8 \pm 0.90\)\\
    $PPR$ & 0.011 & \(-62.33 \pm 0.01\)\\
    $SSIM(U, G)$ & 0.007 & \(-62.32 \pm 0.01\)\\
    $SSIM(U, G, R)$ & 0.696 & \(-57.70 \pm 0.30\)\\
  \end{tabular}
  \label{tab:hist}
\end{table}


\begin{figure}
  \input{./illustrations/scaling-kld.tex}
  \caption{Scaling of number of likelihood calls with Kullback-Leibler
    divergence \({\cal D}\{ \pi, {\cal P}\}\) With colinear offsets
    varying from $10\bm{\mu}$ to $300\bm{\mu}$. The best fit line is
    \(\left[(1.5 \pm 0.2) {\cal D} + (1.7 \pm 0.1)\right]\cdot 10^3 \)
    with determination coefficient \(R^{2} = 0.85\) which indicates
    that \({\cal D}\) is a reliable performance indicator for
    \texttt{PolyChord}.\label{fig:kl-scaling}}
\end{figure}


\begin{figure}
\input{./illustrations/histograms.tex}
\caption{An illustration of the evidence estimate distribution for
  different types of consistent repartitioning. The analytical
  reference is \(\log {\cal Z} = -62 = - \log V(\Psi)\), from
  \cref{eq:def-z}, where \((a,b)=(-6, 6)\cdot 10^{8}\) and
  \(\Sigma=\mathds{1}_{3}\). SSIM is a stochastic superposition of
  Gaussian iPPR (\(G\)), uniform (\(U\)) and resizeable-bounds uniform
  (\(R\)) priors. The likelihood of \(R\) was not properly re-scaled
  in that the effects of truncation were omitted, to demonstrate the
  importance of \cref{eq:partitioning}. \label{fig:hist}}
\end{figure}




\begin{figure}
  \includegraphics[width=0.5\textwidth]{./illustrations/triangle-fit.pdf}
  \caption{An example of a posterior obtained with PPR, based on
    Planck parameter covariance matrix, compared with the Planck
    posterior chains. The differences in the distributions indicate
    variance across different inference runs.
    ${\cal D}\{ {\cal P}, \bar{\cal P}\} \approx 0.01$. The deviation
    is due to a different (smaller) number of live points used, and
    the difference between the correct likelihood and its
    approximation using a Gaussian. \label{fig:overlay-posteriors}}
\end{figure}


\subsection{Simulations}
\subsubsection{Numerical models}

We shall primarily focus on no more than three-dimensional models with
Gaussian likelihoods, as they are sufficiently general to share
similarities with cosmological data analysis, while also being
practical to be investigated under small perturbations.  For this
purpose, we use a uniform baseline prior, and a Gaussian likelihood:
\begin{equation}
  \ln {\cal L}(\bm{\theta}) = \ln {\cal L}^\text{max}- \dfrac{1}{2}{(\bm{\theta} - \bm{\mu})}^{T}\Sigma^{-1}(\bm{\theta}-\bm{\mu}),
\end{equation}
where the covariance matrix \(\bm{\Sigma}\), specifies the extent of
the peak, and the vector \(\bm{\mu}\) --- the location.
\({\cal L}^\text{max}\) is the normalisation factor, which we keep
implicit, for convenience. $\Sigma$ is assumed diagonal, without loss
of generality.

To simulate imperfections we shall consider translation-al offsets
between the proposed prior and the likelihood.


The first test case is an uncorrelated spherical Gaussian posterior
in three dimensions
\begin{equation}
\mathcal{P}(\bm{\theta}) = G(\bm{\theta}; \bm{\mu} =
  (1,2,3),\bm{\Sigma} = \mathds{1}_{3}),
\end{equation}
truncated to a cube of side \(a = 1.2 \cdot 10^{9}\). The
corresponding evidence (\cref{eq:def-z}) is
\(\ln \mathcal{Z}\approx-62.3\). The quantile of this Gaussian
distribution is the one that enters iPPR and PPR's priors as well as
the reference likelihood. All other test cases are dervied from this
Gaussian either via re-scaling, deformation of variances, or
translation. 


\section{Results and Discussion.}\label{sec:results}
The first test was to ensure that the repartitioning was done
correctly, so the Gaussians entering all Gaussian repartitioning
schemes were given with identical variance and mean. Results are shown
in \cref{tab:hist} and \cref{fig:hist}.


The second class of tests involved deforming the prior Gaussians.
Both SSIM (iPPR and uniform) and PPR were resilient with respect to
re-scaling and anisotropic deformation of the likelihood, obtaining
${\cal D}\{ {\cal P}, \bar{\cal P}\} \leq 0.03$. iPPR coped with
situations where ${\cal P}$ was narrower than $\pi$, while failing, in
the opposite case: ${\cal D}\{ {\cal P}, \bar{\cal P}\} \geq 5.5$,
when $\Sigma = 0.3 \mathds{1}_{3}$.

The final test was with regards to translational offsets. Here the
bounding Cube was reduced in size \(a = 2\cdot 10^{3}\) to improve the
run-times of uniform reference runs. The results are shown in
\cref{fig:kl-d,fig:convergence,fig:drift}, and were discussed in
previous sections.

A special case is that shown in \cref{fig:convergence}. The main
notable feature is the inaccuracy of the posterior obtained by PPR. If
the offset is small --- \(O(2\sigma)\), the posterior is shifted. With
a larger offset, e.g. \(O(4\sigma)\), two peaks can be resolved.  Both
errors are compounded by incorrect evidence (see \cref{fig:drift})
PPR: \(\ln {\cal Z}\approx -25.4 \pm 0.2\), vs uniform reference
\(\ln {\cal Z} = -22.7 \pm 0.4\) and SSIM,
\(\ln {\cal Z} = -22.5 \pm 0.3\).


\begin{figure}
  \input{illustrations/benchmark.tex}
  \caption{number of ${\cal L}$ evaluations as a function of the
    number of live points.
    \(\max {\cal D}\{{\cal P}, \bar{\cal P}\} < 1.5\), meaning all
    participating consistent partitions obtained the correct
    posterior. The number of evaluations scales as
    $k\cdot n_\text{live}^{1.1 \pm 0.2}$, where $k$ reduces for faster
    repartitioning schemes. \label{fig:benchmark}}
\end{figure}


It is worthwhile to consider the impact of such a scenario occurring
during practical use of Bayesian inference. If either of the posterior
looks as PPR's marginalised posteriors in \cref{fig:convergence}, the
researcher performing the inference has the following options:
\begin{enumerate}
\item accept the posterior as is~\label[Option]{opt:accept}
\item accept the posterior, but as a less credible result\label[Option]{opt:accept-with-err}
\item reject the PPR result entirely, and perform a run with only a
uniform prior\label[Option]{opt:uniform}
\item readjust the PPR mean and variance using the posterior, and
re-run~\label[Option]{opt:shift}
\item combine PPR with SSIM in mixture with a uniform prior
\end{enumerate}
\Cref{opt:accept-with-err} is a last resort. \Cref{opt:accept} is
adequate for low accuracy applications, provided errors are properly
estimated using e.g.~\texttt{nestcheck} \cite{higson2018nestcheck}.
From \cref{fig:benchmark}, we see that the performance uplift allows
for \cref{opt:shift} to be more efficient than~\ref{opt:uniform},
albeit marginally so.

This is where our technique is most useful: one obtains, as we've
shown in~\cref{fig:convergence}, a more accurate
\({\cal P}(\bm{\theta})\), by using PPR from within SSIM. This results
in a repartitioning scheme that is on average slower than PPR (by
approximately \(18\%\) extra \({\cal L}\) evaluations) within margin
of run-to-run variance of PPR (approximately
\(20\%\))\footnote{Comparison with \cref{fig:benchmark} may be
  miselading, as the error margins there correspond to exact
  coincidence, while the case in question involves an offset of
  $6\mu$. }.

The
performance impact has considerable run-to-run variance, however never
exceeds \(20\%\) extra \({\cal L}\) evaluations, which is an order of
magnitude less than~\vref{opt:uniform,opt:shift} would afford.

\begin{figure}
\includegraphics[width=0.5\textwidth]{./illustrations/convergence.pdf}
\caption{An illustration of offsets affecting ${\cal P}$ under various
  repartitioning schemes. Dotted series represent the prior
  bias. \label{fig:convergence}}
\end{figure}

\begin{figure} \centering
  \begin{subfigure}{0.86\columnwidth}
    \centering

    \input{./illustrations/kullback-leibler.tex}
    \caption{Kullback-Leibler divergence \({\cal D}\) for different
      offsets: Gaussian peaks displaced from \(\bm{\mu}\) by
      \(\text{Offset}\times \bm{\mu}\). Notice that the faster
      repartitioning methods produce a lower value of \({\cal
        D}\). The divergence \({\cal D}\) scales sub-linearly with the
      offset.\label{fig:kl-d}}
\end{subfigure}

\begin{subfigure}{0.86\columnwidth}
  \centering

  \input{./illustrations/evidence-drift.tex}
  
  \caption{An illustration of offsets affecting ${\cal Z}$. The true
    value is constant, mirrored by the mixture: SSIM of PPR and
    reference uniform. PPR alone produces incorrect evidence,
    consistent with \cref{fig:convergence}. Tighter errorbars on SSIM
    are consistent with our observations from
    \cref{fig:hist}.\label{fig:drift}}
\end{subfigure}
\caption{Illustrations of effects of offsets on the correctness
  \ref{fig:drift} and performance \ref{fig:kl-d} of nested sampling
  under consistent posterior repartitioning.}
\end{figure}



Lastly, \textbf{\emph{posterior mass}} --- a measure of convergence
speed \citep{higson2018nestcheck}, is often used in diagnosing nested
sampling. Typical examples of posterior mass for a run with
$\pi=\text{Const.}$ and runs accelerated by posterior repartitioning
are given in \cref{fig:higson}. Notice that the repartitioned series
has a longer extinction phase, as a result of introducing extra
nuisance parameters. Also, the confidence intervals on each parameter
between the uniform and the repartitioned run are identical,
signifying that we have not lost precision.

\begin{figure*}
\includegraphics[width=.9\textwidth]{./illustrations/higson.png}
\caption{plot of the evolution of nested sampling. The \color{red} red
  \color{black} series corresponds to SSIM of iPPR, while the
  \color{blue} blue \color{black} series --- to a reference
  uniform. The horizontal axis of plots in the second column is
  \(\ln X\), where \(X(\mathcal{L}) \in [0,1]\) is the fraction of the
  prior with likelihood greater than \(\mathcal{L}\). The top plot is
  the relative posterior mass. In row $i$ the ${\cal P}(\theta_{i})$
  is plotted. Confidence intervals represented with color
  intensity. \label{fig:higson}}
\end{figure*}

\subsection{Cosmological Simulations.}\label{sec:orgb81c159}
After an initial run of \texttt{Cobaya}, we have obtained the marginalised
posteriors of all the key parameters of the \(\Lambda\)CDM model,
as well as the nuisance parameters.

First, we have performed an inference using the~\cite{Planck} dataset,
with the \(\Lambda\)CDM model. The results of our initial run are
presented in \cref{fig:cosmology}. From these data, under the
assumption that the parameters' posteriors are a correlated Gaussian
distribution, we extract the means $\bm{\mu}$ and the covariance
matrix \(\bm{\Sigma}\).

We use these in a stochastic superpositional mixture of a uniform
$\pi$ used to obtain them originally and a Gaussian iPPR, patched into
\texttt{Cobaya}'s interface to \texttt{PolyChord}. The run was then
performed with identical settings, and the resulting posteriors were
compared: ${\cal D}\{ {\cal P}, \bar{\cal P}\}$ and ${\cal Z}$,
alongside the marginalised posterior plots \cref{fig:cosmology-cmp}. 


\section{Conclusions}\label{sec:orgdf2cbd9}

\subsection{Results}\label{sec:orgc48c55d}
The project's purpose has been to investigate the performance increase
attainable by algorithmic optimisations of the inputs to nested
sampling.We have identified a class of methods based on work by
\cite{chen-ferroz-hobson}, called consistent partitions, fit for this
purpose. We have shown that each consistent partition can accelerate
nested sampling when given an informative proposal.  We have developed
stochastic superpositional isometric mixing (SSIM), to combine several
proposals, into one. When used with nested sampling, SSIM produces
more precise and accurate posteriors, faster than any individual
consistent partition.

We have established the following advantages in using SSIM over PPR:
SSIM admits multiple types of proposal priors, while PPR admits only
one; it permits a broader class of proposals, for example: with
differing domains, while PPR --- only if the domains of the proposals
coincide.  SSIM is abstract: the prior quantile is a superposition of
the constituent priors' quantiles. By contrast, PPR prior quantile
needs to be calculated by the end user for each type of proposal. The
calculation is non-trivial for non-Gaussian proposals. SSIM supports
an unbiased reference (uniform) prior exactly. PPR tends to an
unbiased reference as \(\beta\rightarrow 0 \), but is only truly
unbiased if $\beta=0$, with negligible probability. SSIM, like PPR,
prefers the prior that leads to a higher likelihood, but unlike PPR,
this does not lead to the total exclusion of less-representative
priors.


As a result, faster, but more fragile consistent partitions
(e.g.~iPPR), in conjunction with a standard uniform prior can exceed
more robust but slower PPR in precision accuracy and speed.  When
applied to real-world cosmological parameter estimation, our strategy
of using SSIM of Uniform and iPPR resulted in a significant
performance increase, reducing the run-time requirements of
\texttt{Cobaya} by a factor of 30.

\subsection{Further refinements}\label{sec:org8314ddf}

A purpose-built nested sampler is able to more accurately and more
efficiently make use of the advantages netted by SSIM. Adaptive
sampling strategies, awareness of branching and many more
optimisations require access to the internal state of the sampler. 

We should also explore the implementation of Superpositional mixtures
using quantum computers. Qubits are a natural fit for representing the
branch choice and superposition is an explicit property of Quantum
mechanics.

\subsection{Applications}\label{sec:applications}
The obtained results are general. They can be applied in any area of
any science that relies on Bayesian inference using nested sampling,
e.g.~astronomy \citep{Casado_2016}. SSIM should be considered for
high-performance compute applications in COVID-19 research
(e.g.~\cite{Covid1,Covid2}), as inference in this field is both time
and resource-intensive, while also being time-critical. It may prove
useful for agent-based simulations, with complex Likelihood functions
\citep{Covid2}, similar to Cosmology. Identifying causal links between
policies and incidence of Covid 19 cases, for example is described by
49 parameters.

Note that the asymptotic worst-case time complexity of superpositional
mixtures liberates one to use as many complex models as one likes. For
example: consider two libraries providing a likelihood for
\(\Lambda\)CDM, one which makes multiple approximations (fast), and
one which performs the full calculation (slow). By using the two in a
superpositional mixture, one shall obtain a speedup compared to the
slow run of nested sampling. This is because the slow likelihood is
evaluated only some of the time. It will only be comparable to the
pure slow run if the fast prior were utterly unrepresentative of the
results, which itself is a valuable insight. This may be of particular
interest for further refining \texttt{CLASS} and \texttt{Cobaya}, as
the sheer complexity of the Planck likelihood code is the current
major bottleneck.

Nested sampling can also be applied to inference-related problems,
such as reinforcement learning. The process of training a neural
network involves estimating connection strengths between nodes of said
network. Normally, this is achieved via negative feedback: connections
correlated with the desired behaviour are reinforced, and vice versa
\cite{Kaelbling_1996}. This problem maps neatly onto Bayesian
inference when identifying connections strengths as parameters of a
model, and likelihood --- correlation with desired behaviour. Most
neural networks are trained with uniform priors.


We may also extend Bayesian analysis to \textbf{\emph{consistent
    Bayesian meta-analysis}}. Consider data obtained from multiple
physical processes that are described in one theory with an
overlapping set of parameters $\theta$. As of now, we only perform
separate analyses of each experiment. However, SSIM allows us to
combine these models, and naturally represents consistency in the
posteriors of the shared parameters. As an example, all of the
estimates of the age of the universe may be obtained in one fell swoop
from all the available models and data. This will have the bonus of
highlighting datasets that are incompatible with the overall
conclusion, allowing us to re-evaluate the experimental data as
needed\footnote{Additional, more elaborate explanations shall be
  published in a paper submitted to the \textbf{\emph{Monthly Notices
      of the Royal Astronomical Society}}.}.

Some of our lesser discoveries can also be re-purposed. For example,
Additive mixtures' potential may be unleashed with an algorithm other
than nested sampling that is similar to it in being sensitive to the
partitioning, but does not require the prior quantile.

In conclusion, the new methodology of combining information from many
priors shows great promise in the field of Bayesian inference. It has
demonstrably reduced the run-time of some of the most complex
problems: that of Cosmological Parameter Estimation. A rich field of
research awaits those courageous-enough to follow. It is ours but to point
the way.

\bibliography{bibliography}
\bibliographystyle{mnras}

\begin{landscape}
\begin{figure}
  \centering % Center table
  \input{./illustrations/cosmology.pgf}
  \caption{The marginalised posteriors for \texttt{Cobaya} +
    \texttt{Class}. }\label{fig:cosmology}
\end{figure}
\end{landscape}


\appendix

\section{Nested sampling in detail}\label{sec:ns}
Consider without loss of generality, a prior space \(\Psi\) that is a
unit hypercube, where \(\pi(\bm{\theta}) = \text{Const.}\) Draw
\(n_\text{live}\) random \emph{live points} from the unit
hypercube. If \({\cal L}\) is a well-behaved function, the probability
that two points have the same likelihood is vanishing, so each of them
lies on a \textbf{distinct} iso-likelihood
hyper-surface\footnote{analogy: height on a contour map. }. Each
hyper-surface encloses the fraction
\begin{equation}
\cfrac{1}{n_\text{live}},
\end{equation}
of the total volume of the hypercube on average. More specifically,
each shell's enclosed volume shall have some random deviation \(\Delta\), from
\(\cfrac{1}{n_\text{live}}\), with an associated cumulative
distribution \(P(\Delta)\).

Subsequently, we pick another point at random, requiring that the
likelihood of the new point be higher than the lowest likelihood of
the initial \emph{live point} ensemble. In \citeauthor{Skilling2006}'s
notation, the point with the lowest likelihood becomes \emph{dead} and
the new point becomes is \emph{live}. This is a single iteration of
nested sampling.

Our argument of approximately equal volumes holds for the new
ensemble, so the volume encased in the outer-most shell iteratively
reduces by the same fraction, allows us to approximate said volumes:
\begin{equation}\label{eq:recurrence-relation}
  \begin{array}{rcl}
  X_{0} &=  &1, \\
  X_{1} &= &X_{0} \left(1- \cfrac{1}{n_\text{live}}\right),\\
  & \vdots &, \\
  X_{i} &= &X_{i-1}\left(1- \cfrac{1}{n_\text{live}}\right),\\
  & \vdots, &
\end{array}
\end{equation}
Thus we iteratively pick live points in regions $\{\bm{\theta}\}$ of
high \({\cal L}\), and also estimating the evidence, and stop when the
prior volume encased in the outer shell is lower than a predetermined
fraction e.g: \(0.01\) of the original hypercube volume.

The recurrence relation~\eqref{eq:recurrence-relation} is not exact,
however, \(P(\Delta)\) is a known distribution, dependent on the
\(\dim \Psi\) and \({\cal L}\). Thus, for each \(\epsilon>0\), there
exists \(\delta(\epsilon) >0,\) such that
\(P(\Delta > \delta)<\epsilon.\) Hence, by choosing \(\epsilon\) based
on \(n_\text{live}\), one obtains an estimate of the error
\(\delta\). Propagating these errors allows us to evaluate the prior
volume, ergo: ${\cal Z}$ up to an estimable error.

This is generalised to non-hypercube $\Psi$ and non-uniform $\pi$ via
the prior quantile.

\section{Re-sizeable-bounds uniform prior}\label{sec:resizeable}
In this appendix, we shall highlight why posterior repartitioning is a
misnomer, and why the more general idea of evidence repartitioning is
more fruitful.

As noted in section~\vref{domain-discussion}, the domains of all
functions need to be consistent, otherwise~\vref{eq:bayes} no longer
holds. The mathematical implications of neglecting function domains in
the context of Quantum mechanics has been discussed
by~\cite{Gieres_2000}. However, this does not preclude us from
considering re-parametrisations of $\pi$ and ${\cal L}$ that are
consistent with the same evidence. 

To illustrate, consider a uniform prior with the following
parametrisation:
\begin{equation}
  \hat{\pi}(\bm{\theta}; \beta) = \TopHat(\bm{\theta}; \beta \bm{a}, \beta \bm{b}).
\end{equation}
Although there are no issues when \(\beta>1\) (we set
\({\cal\hat{L}}(\bm{\theta}; \beta>1)=0\)), one can immediately
spot the issues with \(\beta \in (0,1)\); and \(\beta=0\) is
altogether nonsensical.

This issue indicates that the prescription of keeping
\begin{equation}
  \pi {\cal L} = \text{Const.}
\end{equation}
is not complete. Nevertheless, such a scheme may be salvaged if
\cref{eq:partitioning} is taken as the primary, with counter-intuitive
extensions, e.g.~for a point \(\bm{\theta}_{0} \notin \Psi\), we don't
expect
\begin{equation}
{\cal L}(\bm{\theta}_{0}) \rightarrow \infty,
\end{equation}
but as we shall see:
  \begin{equation}
    {\cal L}(\bm{\theta}_{0}) \rightarrow 0.
  \end{equation}
  
  The first crucial step is to recognise that the algorithm draws from
  a unit hypercube with uniform probability, and that the prior is an
  artefact of a coordinate transformation which we referred to as the
  prior quantile.

Let \(u\) be a point in unit hypercube \(\Psi_{C}\). The quantile
defines a mapping functionally dependent on the PDF of the prior

\begin{equation}
  C(\beta)\lbrace \hat{\pi}\rbrace:u \mapsto \bm{\theta},\label{eq:coordinate-transform}
\end{equation}

such that
the uniform distribution of \(\bm{u}\) leads through
\(C_{\beta}\{\hat{\pi}\}(\bm{u})\) to a \(\hat{\pi}(\bm{\theta};\beta)\)
distribution of \(\bm{\theta} \in\Psi(\beta)\).Note that we replaced the
parametrisation of the function \(\hat{\pi}\) with an explicit
parametrisation of the coordinate transformation, specifically
\begin{equation}
  \pi(C(\beta)\{\hat{\pi}\}(u)) \equiv \hat{\pi}(\bm{\theta}; \beta),
\end{equation}
where 
\begin{equation}
  \hat{\pi} =  \pi \circ C(\beta) \{ \pi \} 
\end{equation}
is a parameterised distribution resulting from a parameterised
coordinate transformation of an un-parameterised prior PDF. We shall
have~\vref{eq:bayes} hold only in the hypercube
\begin{equation}
{\cal \hat{P}}(u) = {\cal P}(C(\beta_{0}){\hat{\pi}}^{-1}(\bm{\theta})) = \cfrac{\hat{\pi} (u) {\cal \hat{L}}(u)}{\int_{\Psi}{\cal \hat{L}}(u) \hat{\pi}(u) du},
\end{equation}
which is always true, regardless of the repartitioning
scheme. Trivially, the functional form of \(P(\bm{\theta})\) is not the same
as \(P(u)\); it's related via a co-ordinate transform, which in our
case contributes a Jacobian factor \(J(\beta)\{\hat{\pi}\}\) to the
evidence. But since we're interested in the posterior in the
coordinates \(\bm{\theta}\), given by the transformation \(C(\beta_{0})\{\hat{\pi}\}\),
while the prior and the likelihood are in the from corresponding
to \(\beta\).

Finally, 
\begin{equation}
 {\cal P}(\bm{\theta}) = \cfrac{J(\beta_{0})}{J(\beta)} \cfrac{\pi(\bm{\theta}; \beta) {\cal L}(\bm{\theta}; \beta)}{\int \pi(\bm{\theta}; \beta) {\cal L}(\bm{\theta}; \beta) d \bm{\theta}}.
\end{equation}
So we expect that for the simple case of scaling the uniform box
prior with \(\beta\), that we need to re-scale the likelihood by
\(\beta^{2n}\). The second Jacobian factor enters the likelihood because
we have normalised \(\pi(\bm{\theta})\), but not \(\pi(\bm{\theta}; \beta)\). This is hinted at in
the notation, (no tilde), and when accounted for, gives  the correct
posterior and evidence as seen in the experiments.

\subsubsection{Argument resizing}\label{sec:orgfe92f25}

A class of convenient repartitioning schemes is one where the prior's
argument is re-sized e.g:
\begin{equation}
  \label{eq:argument-resize}
  \hat{\pi} (\bm{\theta}; \beta) = \pi (f(\beta)\cdot\bm{\theta}),
\end{equation}
where \(f(\beta)\) is some function.

These are quite convenient as the quantile is straightforwardly
related to the quantile of the original:
\begin{equation}
  \label{eq:quantile-stuff}
  C\{\hat{\pi}\} = f(\beta) C\{\frac{\pi}{f(\beta)}\}.
\end{equation}
We're already acquainted with an exemplar from this class: PPR if
\( \pi (\bm{\theta}) \propto \exp [P_{n}(\theta)]\) where $P_{n}$ is a
polynomial.


\section{Objectivity\label{sec:objectivity}}
We shall elaborate here on the meaning of \cref{obj-prop}, and why
\cref{eq:partitioning} and \cref{eq:bayes}, don't guarantee the
correct \( {\cal P}(\bm{\theta})\) and ${\cal Z}$.  It is a
peculiarity of nested sampling. It is much faster than e.g.~uniform
rasterisation, because instead of evaluating ${\cal Z}$ exactly, it
uses a statistical argument to successively approximate ${\cal
  Z}$. The four properties are necessary for errors in ${\cal Z}$ to
accumulate more slowly than is necessary to have moved all of the live
points onto the posterior peak(s). In \cref{fig:convergence}, we see a
particular case that highlights what happens if \cref{obj-prop} is
violated.

Specifically, the arrangement of prior and posterior is such that
points lie in regions of average likelihood. Along the $\theta_{1}$
direction, the likelihood is so large that any small displacement
within the prior in the direction of the posterior accounts for a
large portion of the evidence. This is seen in \cref{fig:higson},
where the bulk of the evidence is gathered early.

However, along $\theta_{3}$ there is a significant difference in the
likelihood, so a small fraction of the live points do indeed get moved
onto the posterior. Nonetheless, we reached the termination criterion
before points could have been moved fully, producing an incorrect
marginalised posterior.  This situation is contrived, as it required
fine-tuning. The odds of this occurring in practice are minuscule, and
the presence of \cref{fig:convergence} does not invalidate the
importance of PPR.


This highlights a crucial problem with PPR (and later, additive
mixtures) that the probability of having an unbiased prior in some
region is negligible\footnote{ \(P(\beta=0)\) to be precise.}. There
is always a bias: points are always more likely to spawn and be moved
towards the prior peak. When using repartitioning, we need to ensure
that this bias is weaker than the bias towards the posterior. The
latter is implementation-dependent, \texttt{MultiNest} is more prone
to such errors.

However, crucially, we will have obtained a smaller evidence with a
larger error: this is the only way in which the posterior may appear
the way it does in \cref{fig:convergence} without violating
\cref{eq:bayes}. Corollary: we will have known if the posterior is
dubious. In \cref{sec:results}, we discussed how to proceed should
such a scenario arise.

\section{Making PPR robust again}
The shortcomings of PPR, may be somewhat mitigated if the goal is to
ensure stable convergence, rather than maximally improving
performance. Start by noting that $\beta$ according to nested sampling
is nothing but an extra nuisance parameter: it requires a prior. This
prior plays a pivotal role in PPR's stability. In fact there is an
obvious, maximally stable, choice:
\begin{equation}
  \label{}
\hat{\pi}(\bm{\theta}; \beta) = \delta(\beta) \hat{\pi}(\bm{\theta}), 
\end{equation}
which is exactly the uniform prior. It is unbiased: any region inside
the boundaries, and excluding the boundaries is equally likely to be
sampled. This is because $\pi^{\beta}(\bm{\theta})$ is uniform, when $\beta=0$, and
\begin{equation}\label{eq:PPR-uniform}
P(\beta=0) = \int_{\mathbb{R}} \delta(\beta) d\beta = 1 \ne 0. 
\end{equation}
By adding extra $\delta$-functions we can simulate a fixed Stochastic
isometric superposition. Similarly, by allowing the weights of these
$\delta$-functions to vary, we can simulate a superpositional
isometric mixture of priors related by power law, e.g.
\begin{equation}
  \label{}
  \hat{\pi}(\beta; \bm{w}) = w_{0}\delta(\beta_{0}) + w_{1}\delta(\beta_{1})+\ldots
\end{equation}
These are known to be more robust than PPR alone, so a choice of
$\hat{\pi}(\beta)$ that makes PPR distinct and useful should exist.

A clue lies in that $\beta=0$ is special. So a sensible next step
would be to try
\begin{equation}
  \label{}
\hat{\pi}(\beta; w) = w \delta(\beta) + (1-w). 
\end{equation}
This is equivalent to a uniform $\beta$ PPR (\(1-w\) in a stochastic
mixture with a uniform prior ($\delta(\beta)$). In general the second
term can be any function, and it would still be a superpositional
mixture of PPR with that function as the prior in $\beta$ and a
uniform.

What about
\begin{equation}
\hat{\pi}(\beta; \sigma) = G(\beta; 0, \sigma)?
\end{equation}
For numerical simulations, it has some probability (dependent on
$\sigma \ne 0$) to be unbiased. It is weakly biased, as
\(P(\beta=0) \rightarrow 0\) with increasing resolution:
\begin{equation}
  \label{eq:p0}
   P(\beta=0) = \lim_{\epsilon\rightarrow 0} \int_{-\epsilon}^{\epsilon}\hat{\pi}(\beta) = 0
\end{equation}
but it is already an improvement over a uniform prior (in $\beta$).

Sadly, \cref{eq:p0} highlights why priors $\hat{\pi}(\beta)$ can never
outperform SSIM in producing an unbiased prior. If
$\hat{\pi}(\bm{\theta}, \beta)$ is such that \(P(\beta=0) = w \ne 0\)
it is equivalent to a superpositional isometric mixture of uniform
(with weight \(w\)) and a PPR with prior
$\tilde{\pi}(\beta) = \hat{\pi}(\beta) - w \delta(\beta)$.

So, superpositional mixtures can be implemented using PPR by varying
the prior in $\beta$.










\end{document}